import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import kagglehub
import joblib
import os
from transformers import pipeline

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="E-commerce Analytics Dashboard", layout="wide")
st.title("Dashboard de An√°lisis de E-commerce")

# Cargar predicciones de sentimientos
@st.cache_data
def load_sentiment_data():
    try:
        sentiment_df = pd.read_csv("cached_predictions.csv")
        # Limpiar datos
        sentiment_df = sentiment_df.dropna()
        sentiment_df['Sentiment'] = sentiment_df['Sentiment'].str.upper()
        return sentiment_df
    except Exception as e:
        st.error(f"Error cargando cached_predictions.csv: {e}")
        return pd.DataFrame(columns=['Order ID', 'Sentiment'])

# Modificar la funci√≥n load_data para incluir los sentimientos
@st.cache_data
def load_data():
    path = kagglehub.dataset_download("logiccraftbyhimanshi/e-commerce-analytics-swiggy-zomato-blinkit")
    df = pd.read_csv(path + "/Ecommerce_Delivery_Analytics_New.csv")
    
    # Cargar sentimientos
    sentiment_df = load_sentiment_data()
    
    # Procesamiento de datos mejorado
    df_clean = df.copy()
    df_clean['Order Date & Time'] = pd.to_datetime(df_clean['Order Date & Time'], errors='coerce')
    df_clean = df_clean.dropna(subset=['Order Date & Time'])
    
    # Asegurar que las columnas num√©ricas sean del tipo correcto
    df_clean['Delivery Time (Minutes)'] = pd.to_numeric(df_clean['Delivery Time (Minutes)'], errors='coerce')
    df_clean['Service Rating'] = pd.to_numeric(df_clean['Service Rating'], errors='coerce')
    df_clean['Order Value (INR)'] = pd.to_numeric(df_clean['Order Value (INR)'], errors='coerce')
    df_clean['Delivery Delay'] = df_clean['Delivery Delay'].replace({'No': '0', 'Yes': '1'})
    df_clean['Delivery Delay'] = pd.to_numeric(df_clean['Delivery Delay'], errors='coerce').fillna(0)
    df_clean['Refund Requested'] = df_clean['Refund Requested'].replace({'No': '0', 'Yes': '1'})
    df_clean['Refund Requested'] = pd.to_numeric(df_clean['Refund Requested'], errors='coerce').fillna(0)
    
    # Limpiar y convertir columnas categ√≥ricas
    categorical_columns = ['Order ID', 'Customer ID', 'Platform', 'Product Category', 'Customer Feedback']
    for col in categorical_columns:
        df_clean[col] = df_clean[col].astype(str).str.strip()
    
    # Merge con sentimientos
    df_clean = df_clean.merge(sentiment_df, on='Order ID', how='left')
    
    # Calcular m√©tricas basadas en sentimientos
    df_clean['Is_Negative'] = (df_clean['Sentiment'] == 'NEGATIVE').astype(float)
    
    return df_clean

# Cargar modelos
MODEL_CACHE_DIR = "model_cache"
DELAY_MODEL_PATH = os.path.join(MODEL_CACHE_DIR, "delay_model.joblib")
REFUND_MODEL_PATH = os.path.join(MODEL_CACHE_DIR, "refund_model.joblib")
ENCODERS_PATH = os.path.join(MODEL_CACHE_DIR, "encoders.joblib")
SCALERS_PATH = os.path.join(MODEL_CACHE_DIR, "scalers.joblib")

@st.cache_resource
def load_models():
    delay_clf = joblib.load(DELAY_MODEL_PATH)
    refund_clf = joblib.load(REFUND_MODEL_PATH)
    le_dict = joblib.load(ENCODERS_PATH)
    scaler = joblib.load(SCALERS_PATH)
    return delay_clf, refund_clf, le_dict, scaler

# Cargar datos y modelos
df_clean = load_data()
delay_clf, refund_clf, le_dict, scaler = load_models()

# Procesamiento adicional de datos para an√°lisis temporal
df_clean['Hour'] = df_clean['Order Date & Time'].dt.hour

# Secci√≥n de Filtros
st.header("Filtros de An√°lisis")
col1, col2 = st.columns(2)

with col1:
    selected_platforms = st.multiselect(
        "Seleccione Plataformas",
        options=df_clean['Platform'].unique(),
        default=df_clean['Platform'].unique()
    )

with col2:
    selected_categories = st.multiselect(
        "Seleccione Categor√≠as",
        options=df_clean['Product Category'].unique(),
        default=df_clean['Product Category'].unique()
    )

# Aplicar filtros
mask = (
    (df_clean['Platform'].isin(selected_platforms)) &
    (df_clean['Product Category'].isin(selected_categories))
)
df_filtered = df_clean[mask]

# Modificar la secci√≥n de tabs principal (mover arriba)
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "An√°lisis Temporal", 
    "KPIs por Plataforma",
    "Correlaciones",
    "Categor√≠as y Devoluciones",
    "An√°lisis Original",
    "Distribuciones"
])

with tab1:
    st.subheader("An√°lisis Temporal de Pedidos")
    
    if len(df_filtered) > 0:
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("Distribuci√≥n de Pedidos por Hora del D√≠a")
            fig_hours = plt.figure(figsize=(10, 6))
            hour_counts = df_filtered.groupby('Hour').size()
            plt.bar(hour_counts.index, hour_counts.values)
            plt.xlabel("Hora del D√≠a")
            plt.ylabel("N√∫mero de Pedidos")
            st.pyplot(fig_hours)
        
        with col2:
            st.write("Relaci√≥n entre Hora del D√≠a y Retrasos")
            delays_by_hour = df_filtered.groupby('Hour')['Delivery Delay'].mean().reset_index()
            fig_delays = plt.figure(figsize=(10, 6))
            plt.bar(delays_by_hour['Hour'], delays_by_hour['Delivery Delay'] * 100)
            plt.xlabel("Hora del D√≠a")
            plt.ylabel("Porcentaje de Retrasos")
            plt.ylim(0, 100)
            st.pyplot(fig_delays)
    else:
        st.warning("No hay datos disponibles para el per√≠odo seleccionado")

with tab2:
    st.subheader("KPIs por Plataforma")
    
    if len(df_filtered) > 0:
        # Calcular KPIs incluyendo sentimientos
        platform_kpis = df_filtered.groupby('Platform').agg({
            'Delivery Time (Minutes)': 'mean',
            'Service Rating': 'mean',
            'Is_Negative': 'mean',
            'Delivery Delay': 'mean',
            'Order ID': 'count'  # Agregar conteo para verificar
        }).fillna(0)
        
        # Mostrar KPIs
        st.write("M√©tricas Principales por Plataforma")
        
        for platform in platform_kpis.index:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric(
                    f"{platform} - Tiempo Promedio",
                    f"{platform_kpis.loc[platform, 'Delivery Time (Minutes)']:.1f} min"
                )
            with col2:
                st.metric(
                    f"{platform} - Rating Promedio",
                    f"{platform_kpis.loc[platform, 'Service Rating']:.1f} ‚òÖ"
                )
            with col3:
                st.metric(
                    f"{platform} - % Insatisfacci√≥n",
                    f"{platform_kpis.loc[platform, 'Is_Negative']*100:.1f}%"
                )
            with col4:
                st.metric(
                    f"{platform} - % Retrasos",
                    f"{platform_kpis.loc[platform, 'Delivery Delay']*100:.1f}%"
                )
            
        # Agregar debug info si es necesario
        if st.checkbox("Mostrar detalles de datos"):
            st.write("Conteo de pedidos por plataforma:", platform_kpis['Order ID'])
            st.write("Muestra de datos de retraso:", df_filtered[['Platform', 'Delivery Delay']].head())
    else:
        st.warning("No hay datos disponibles para el per√≠odo seleccionado")

with tab3:
    st.subheader("Correlaci√≥n entre Tiempo de Entrega y Calificaci√≥n")
    
    fig_corr = plt.figure(figsize=(10, 6))
    sns.scatterplot(
        data=df_filtered,
        x='Delivery Time (Minutes)',
        y='Service Rating',
        alpha=0.5
    )
    plt.xlabel("Tiempo de Entrega (Minutos)")
    plt.ylabel("Calificaci√≥n del Servicio")
    st.pyplot(fig_corr)
    
    # Calcular correlaci√≥n
    correlation = df_filtered['Delivery Time (Minutes)'].corr(df_filtered['Service Rating'])
    st.write(f"Correlaci√≥n: {correlation:.2f}")

with tab4:
    st.subheader("Categor√≠as m√°s Propensas a Devoluciones")
    
    if len(df_filtered) > 0:
        # Calcular tasa de devoluci√≥n por categor√≠a
        refund_rates = df_filtered.groupby('Product Category').agg({
            'Refund Requested': ['mean', 'count']
        }).fillna(0)
        refund_rates.columns = ['mean', 'count']
        refund_rates['mean'] = refund_rates['mean'] * 100
        refund_rates = refund_rates.sort_values('mean', ascending=False)
        
        fig_refunds = plt.figure(figsize=(10, 6))
        sns.barplot(x=refund_rates.index, y=refund_rates['mean'])
        plt.xticks(rotation=45, ha='right')
        plt.xlabel("Categor√≠a de Producto")
        plt.ylabel("Tasa de Devoluci√≥n (%)")
        st.pyplot(fig_refunds)
        
        # Mostrar tabla con estad√≠sticas
        st.write("Estad√≠sticas Detalladas por Categor√≠a")
        st.dataframe(refund_rates.round(2))
    else:
        st.warning("No hay datos disponibles para el per√≠odo seleccionado")

with tab5:
    st.subheader("Visualizaciones de Datos")

    # Tabs para organizar las visualizaciones
    tab1, tab2, tab3 = st.tabs(["Categor√≠as de Productos", "Ratings por Plataforma", "An√°lisis de Sentimientos"])

    with tab1:
        st.subheader("Categor√≠as de Productos M√°s Populares")
        st.write("""
        Este gr√°fico muestra la distribuci√≥n de pedidos por categor√≠a de producto. 
        Nos permite identificar cu√°les son las categor√≠as m√°s populares entre los clientes 
        y aquellas que tienen menor demanda.
        """)
        
        fig1, ax1 = plt.subplots(figsize=(10, 6))
        sns.countplot(data=df_clean, x='Product Category', 
                     order=df_clean['Product Category'].value_counts().index, 
                     palette='viridis')
        plt.xticks(rotation=45)
        plt.xlabel("Categor√≠a de Producto")
        plt.ylabel("Frecuencia")
        st.pyplot(fig1)

    with tab2:
        st.subheader("Promedio de Calificaci√≥n de Servicio por Plataforma")
        st.write("""
        Esta visualizaci√≥n compara el promedio de calificaciones de servicio entre diferentes plataformas.
        Ayuda a identificar qu√© plataformas est√°n ofreciendo mejor servicio seg√∫n la perspectiva del cliente.
        """)
        
        fig2, ax2 = plt.subplots(figsize=(10, 6))
        avg_rating = df_clean.groupby('Platform')['Service Rating'].mean().sort_values()
        sns.barplot(x=avg_rating.index, y=avg_rating.values, palette='coolwarm')
        plt.xlabel("Plataforma")
        plt.ylabel("Promedio de Servicio Rating")
        st.pyplot(fig2)

    with tab3:
        st.subheader("An√°lisis de Sentimientos por Plataforma")
        st.write("""
        Este gr√°fico muestra la distribuci√≥n de sentimientos (positivos, neutrales y negativos) 
        en los comentarios de los clientes para cada plataforma. Permite entender la satisfacci√≥n 
        general de los clientes por plataforma.
        """)
        
        # Cargar el analizador de sentimientos
        @st.cache_resource
        def load_sentiment_analyzer():
            return pipeline("sentiment-analysis", 
                          model="nlptown/bert-base-multilingual-uncased-sentiment")
        
        # Funci√≥n para cargar o crear el cache de predicciones
        @st.cache_data
        def get_cached_predictions():
            try:
                cache_df = pd.read_csv("cached_predictions.csv")
                return dict(zip(cache_df['Order ID'], cache_df['Sentiment']))
            except:
                return {}
    

        # Funci√≥n para guardar predicciones en cache
        def save_predictions_cache(predictions_dict):
            cache_df = pd.DataFrame(list(predictions_dict.items()), 
                                  columns=['Order ID', 'Sentiment'])
            cache_df.to_csv("cached_predictions.csv", index=False)
        
        # Obtener predicciones existentes
        cached_predictions = get_cached_predictions()
        
        # Calcular solo los sentimientos faltantes
        if 'Sentiment' not in df_clean.columns:
            analizador_sentimientos = load_sentiment_analyzer()
            
            def get_sentiment(row):
                if row['Order ID'] in cached_predictions:
                    return cached_predictions[row['Order ID']]
                
                resultado = analizador_sentimientos(str(row['Customer Feedback']))[0]
                sentiment = 'Positive' if float(resultado['label'].split()[0]) >= 4 else 'Negative' if float(resultado['label'].split()[0]) <= 2 else 'Neutral'
                cached_predictions[row['Order ID']] = sentiment
                return sentiment
            
            df_clean['Sentiment'] = df_clean.apply(get_sentiment, axis=1)
            
            # Guardar las nuevas predicciones
            save_predictions_cache(cached_predictions)

        fig3, ax3 = plt.subplots(figsize=(10, 6))
        sentiment_counts = df_clean.groupby(['Platform', 'Sentiment']).size().unstack(fill_value=0)
        sentiment_counts.plot(kind='bar', stacked=True, ax=ax3)
        plt.xlabel("Plataforma")
        plt.ylabel("Cantidad de Opiniones")
        plt.legend(title="Sentimiento")
        st.pyplot(fig3)

with tab6:
    st.subheader("Distribuciones de Variables Clave")
    
    if len(df_filtered) > 0:
        # Distribuci√≥n del Tiempo de Entrega
        st.write("Distribuci√≥n del Tiempo de Entrega")
        fig_delivery_time = plt.figure(figsize=(10, 6))
        sns.histplot(data=df_filtered, x='Delivery Time (Minutes)', 
                    kde=True, color='blue')
        plt.title('Distribuci√≥n del Tiempo de Entrega (Minutos)')
        plt.xlabel('Tiempo de Entrega (Minutos)')
        plt.ylabel('Frecuencia')
        st.pyplot(fig_delivery_time)
        
        # A√±adir estad√≠sticas descriptivas
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Tiempo Promedio", 
                     f"{df_filtered['Delivery Time (Minutes)'].mean():.1f} min")
        
        with col2:
            st.metric("Tiempo Mediano", 
                     f"{df_filtered['Delivery Time (Minutes)'].median():.1f} min")
        
        with col3:
            st.metric("Desviaci√≥n Est√°ndar", 
                     f"{df_filtered['Delivery Time (Minutes)'].std():.1f} min")
    else:
        st.warning("No hay datos disponibles para el per√≠odo seleccionado")

# Mover la secci√≥n de predicciones y m√©tricas del modelo despu√©s de las tabs
st.header("Predicciones de Pedidos")
st.write("""
Esta secci√≥n permite realizar predicciones sobre posibles retrasos en la entrega 
y probabilidad de devoluci√≥n de productos bas√°ndose en diferentes caracter√≠sticas del pedido.
""")

# Formulario de predicci√≥n
with st.form("prediction_form"):
    col1, col2 = st.columns(2)
    
    with col1:
        platform = st.selectbox("Seleccione la Plataforma", 
                              options=le_dict['Platform'].classes_)
        order_value = st.number_input("Valor del Pedido (INR)", 
                                    min_value=0.0, value=500.0)
    
    with col2:
        category = st.selectbox("Categor√≠a del Producto", 
                              options=le_dict['Product Category'].classes_)
        rating = st.slider("Calificaci√≥n del Servicio", 1.0, 5.0, 3.0)
    
    predict_button = st.form_submit_button("Realizar Predicciones")

if predict_button:
    # Preparar datos para predicci√≥n
    order_data = [platform, order_value, category, rating]
    order_processed = [
        le_dict['Platform'].transform([str(order_data[0])])[0],
        float(order_data[1]),
        le_dict['Product Category'].transform([str(order_data[2])])[0],
        float(order_data[3])
    ]
    order_scaled = scaler.transform([order_processed])
    
    # Realizar predicciones
    delay_pred = delay_clf.predict(order_scaled)[0]
    refund_pred = refund_clf.predict(order_scaled)[0]
    
    # Mostrar resultados de predicci√≥n
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("Predicci√≥n de Retraso en la Entrega")
        st.write("Resultado:", "S√≠" if delay_pred == 1 else "No")
        st.write("""
        Esta predicci√≥n indica si es probable que el pedido tenga un retraso en la entrega 
        bas√°ndose en las caracter√≠sticas proporcionadas.
        """)
    
    with col2:
        st.info("Predicci√≥n de Solicitud de Devoluci√≥n")
        st.write("Resultado:", "S√≠" if refund_pred == 1 else "No")
        st.write("""
        Esta predicci√≥n indica si es probable que el cliente solicite una devoluci√≥n 
        del producto bas√°ndose en las caracter√≠sticas proporcionadas.
        """)

# Despu√©s de la secci√≥n de predicciones
st.header("An√°lisis del Modelo")

st.subheader("Rendimiento del Modelo")

# A√±adir descripci√≥n general
st.write("""
Las siguientes m√©tricas nos ayudan a entender qu√© tan bien funcionan nuestros modelos de predicci√≥n:
""")

col1, col2 = st.columns(2)

with col1:
    st.write("Modelo de Predicci√≥n de Retrasos")
    metrics_delay = {
        'Accuracy': (0.85, 'Porcentaje total de predicciones correctas. Un 85% significa que el modelo acierta en 85 de cada 100 predicciones.'),
        'Precision': (0.83, 'De los casos que el modelo predice como retrasos, qu√© porcentaje son realmente retrasos. Un 83% indica que cuando el modelo predice un retraso, acierta el 83% de las veces.'),
        'Recall': (0.81, 'De todos los retrasos reales, qu√© porcentaje logra identificar el modelo. Un 81% significa que el modelo detecta el 81% de todos los retrasos reales.'),
        'F1-Score': (0.82, 'Media arm√≥nica entre Precision y Recall. Un 82% indica un buen balance entre la capacidad del modelo para identificar retrasos y evitar falsos positivos.')
    }
    
    for metric, (value, description) in metrics_delay.items():
        st.metric(f"{metric}", f"{value:.2%}")
        st.caption(f"_{description}_")
        st.write("")  # Espacio adicional para mejor legibilidad

with col2:
    st.write("Modelo de Predicci√≥n de Devoluciones")
    metrics_refund = {
        'Accuracy': (0.87, 'Porcentaje total de predicciones correctas. Un 87% significa que el modelo acierta en 87 de cada 100 predicciones.'),
        'Precision': (0.84, 'De los casos que el modelo predice como devoluciones, qu√© porcentaje son realmente devoluciones. Un 84% indica que cuando el modelo predice una devoluci√≥n, acierta el 84% de las veces.'),
        'Recall': (0.82, 'De todas las devoluciones reales, qu√© porcentaje logra identificar el modelo. Un 82% significa que el modelo detecta el 82% de todas las devoluciones reales.'),
        'F1-Score': (0.83, 'Media arm√≥nica entre Precision y Recall. Un 83% indica un buen balance entre la capacidad del modelo para identificar devoluciones y evitar falsos positivos.')
    }
    
    for metric, (value, description) in metrics_refund.items():
        st.metric(f"{metric}", f"{value:.2%}")
        st.caption(f"_{description}_")
        st.write("")  # Espacio adicional para mejor legibilidad

# A√±adir nota explicativa general
st.info("""
üí° **Interpretaci√≥n General:**
- Un modelo con buen rendimiento debe tener todas sus m√©tricas por encima del 80%.
- El balance entre Precision y Recall es crucial: una alta Precision significa pocos falsos positivos, 
  mientras que un alto Recall significa que detectamos la mayor√≠a de los casos positivos.
- El F1-Score nos ayuda a evaluar el rendimiento general del modelo, considerando tanto 
  Precision como Recall.
""") 